# YOLOv3
## Bounding Box
<p align="center"><img src="https://github.com/em-1001/YOLOv3-CIoU/assets/80628552/b7058b48-1120-409e-ae7c-1c5ab8b09159">


YOLOv2 ë¶€í„° Anchor box(prior box)ë¥¼ ë¯¸ë¦¬ ì„¤ì •í•˜ì—¬ ìµœì¢… bounding box ì˜ˆì¸¡ì— í™œìš©í•œë‹¤. ìœ„ ê·¸ë¦¼ì—ì„œëŠ” $b_x, b_y, b_w, b_h$ê°€ ìµœì¢…ì ìœ¼ë¡œ ì˜ˆì¸¡í•˜ê³ ì í•˜ëŠ” bounding boxì´ë‹¤. ê²€ì€ ì ì„ ì€ ì‚¬ì „ì— ì„¤ì •ëœ Anchor boxë¡œ ì´ Anchor boxë¥¼ ì¡°ì •í•˜ì—¬ íŒŒë€ìƒ‰ì˜ bounding boxë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ í•œë‹¤.   

ëª¨ë¸ì€ ì§ì ‘ì ìœ¼ë¡œ $b_x, b_y, b_w, b_h$ë¥¼ ì˜ˆì¸¡í•˜ì§€ ì•Šê³  $t_x, t_y, t_w, t_h$ë¥¼ ì˜ˆì¸¡í•˜ê²Œ ëœë‹¤. 
ë²”ìœ„ì œí•œì´ ì—†ëŠ” $t_x, t_y$ì— sigmoid($\sigma$)ë¥¼ ì ìš©í•´ì£¼ì–´ 0ê³¼ 1ì‚¬ì˜ ê°’ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ê³ , ì´ë¥¼ í†µí•´ bboxì˜ ì¤‘ì‹¬ ì¢Œí‘œê°€ 1ì˜ í¬ê¸°ë¥¼ ê°–ëŠ” í˜„ì¬ cellì„ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡ í•´ì¤€ë‹¤. ì—¬ê¸°ì— offsetì¸ $c_x, c_y$ë¥¼ ë”í•´ì£¼ë©´ ìµœì¢…ì ì¸ bboxì˜ ì¤‘ì‹¬ ì¢Œí‘œë¥¼ ì–»ê²Œ ëœë‹¤.    
$b_w, b_h$ì˜ ê²½ìš° ë¯¸ë¦¬ ì •í•´ë‘” Anchor boxì˜ ë„ˆë¹„ì™€ ë†’ì´ë¥¼ ì–¼ë§Œí¼ì˜ ë¹„ìœ¨ë¡œ ì¡°ì ˆí•  ì§€ë¥¼ Anchorì™€ $t_w, t_h$ì— ëŒ€í•œ log scaleì„ ì´ìš©í•´ êµ¬í•œë‹¤. 

YOLOv2ì—ì„œëŠ” bboxë¥¼ ì˜ˆì¸¡í•  ë•Œ $t_x, t_y, t_w, t_h$ë¥¼ ì˜ˆì¸¡í•œ í›„ ê·¸ë¦¼ì—ì„œì˜ $b_x, b_y, b_w, b_h$ë¡œ ë³€í˜•í•œ ë’¤ $L_2$ lossë¥¼ í†µí•´ í•™ìŠµì‹œì¼°ì§€ë§Œ, YOLOv3ì—ì„œëŠ” ground truthì˜ ì¢Œí‘œë¥¼ ê±°ê¾¸ë¡œ $\hat{t}_ {âˆ—}$ë¡œ ë³€í˜•ì‹œì¼œ ì˜ˆì¸¡í•œ $t_{âˆ—}$ì™€ ì§ì ‘ $L_1$ lossë¡œ í•™ìŠµì‹œí‚¨ë‹¤. ground truthì˜ $x, y$ì¢Œí‘œì˜ ê²½ìš° ì•„ë˜ì™€ ê°™ì´ ë³€í˜•ë˜ê³ , 

$$
\begin{aligned}
&b_{âˆ—}= \sigma(\hat{t}_ {âˆ—}) + c_{âˆ—}\\      
&\sigma(\hat{t}_ {âˆ—}) = b_{âˆ—} - c_{âˆ—}\\      
&\hat{t}_ {âˆ—} = \sigma^{-1}(b_{âˆ—} - c_{âˆ—})
\end{aligned}$$

$w, h$ëŠ” ì•„ë˜ì™€ ê°™ì´ ë³€í˜•ëœë‹¤. 

$$\hat{t}_ {âˆ—} = \ln\left(\frac{b_{âˆ—}}{p_{âˆ—}}\right)$$

ê²°ê³¼ì ìœ¼ë¡œ $x, y, w, h$ lossëŠ” ground truthì¸ $\hat{t}_ {âˆ—}$ prediction valueì¸ ${t}_ {âˆ—}$ì‚¬ì´ì˜ ì°¨ì´ $\hat{t}_ {âˆ—} - {t}_ {âˆ—}$ë¥¼ í†µí•œ Sum-Squared Error(SSE)ë¡œ êµ¬í•´ì§„ë‹¤. 

## Model
<p align="center"><img src="https://github.com/em-1001/YOLOv3-CIoU/assets/80628552/c285e2fe-0ae5-4a62-8a9f-ef0824ab6575" height="35%" width="35%"></p>

ëª¨ë¸ì˜ backboneì€ $3 \times 3$, $1 \times 1$ Residual connectionì„ ì‚¬ìš©í•˜ë©´ì„œ ìµœì¢…ì ìœ¼ë¡œ 53ê°œì˜ conv layerë¥¼ ì‚¬ìš©í•˜ëŠ” **Darknet-53** ì„ ì´ìš©í•œë‹¤. Darknet-53ì˜ Residual blockì•ˆì—ì„œë„ bottleneck êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ë©°, inputì˜ channelì„ ì¤‘ê°„ì— ë°˜ìœ¼ë¡œ ì¤„ì˜€ë‹¤ê°€ ë‹¤ì‹œ ë³µêµ¬ì‹œí‚¨ë‹¤. ì´ë•Œ Residual blockì˜ $1 \times 1$ convëŠ” $s=1, p=0$ ì´ê³ , $3 \times 3$ convëŠ” $s=1, p=1$ì´ë‹¤. 

YOLOv3 modelì˜ íŠ¹ì§•ì€ ë¬¼ì²´ì˜ scaleì„ ê³ ë ¤í•˜ì—¬ 3ê°€ì§€ í¬ê¸°ì˜ outputì´ ë‚˜ì˜¤ë„ë¡ FPNê³¼ ìœ ì‚¬í•˜ê²Œ ì„¤ê³„í•˜ì˜€ë‹¤ëŠ” ê²ƒì´ë‹¤. ìš°ì„  feature extractorì—ì„œ ê° scaleì„ ìœ„í•œ tensorë¥¼ ë½‘ì•„ë‚¸ë‹¤. ê·¸ë¦¬ê³  ê° scaleë³„ë¡œ ë½‘ì•„ë‚¸ tensorì— ëŒ€í•´ FPNê³¼ ìœ ì‚¬í•˜ê²Œ convë¥¼ ê±°ì³ ê° scaleì— í•´ë‹¹í•˜ëŠ” ìµœì¢… tensorë¥¼ ë§Œë“¤ì–´ë‚¸ë‹¤. ëª¨ë¸ì€ ê° scaleë³„ë¡œ 3ê°œì˜ boxë¥¼ ì˜ˆì¸¡í•˜ê³  ê° scaleì— ë”°ë¼ ë‚˜ì˜¤ëŠ” ìµœì¢… tensorì˜ í˜•íƒœëŠ” $N \times N \times \left[3 \cdot (4+1+80)\right]$ì´ë‹¤. ì—¬ê¸°ì„œ $4$ëŠ” bounding box offset $(x, y, w, h)$, $1$ì€ objectness prediction, $80$ì€ classì˜ ìˆ˜ ì´ë‹¤. ì´ë ‡ê²Œ ê° í¬ê¸°ë³„ë¡œ feature mapì„ êµ¬í•˜ê³  2 layer í›„ì— $2\times$ë¡œ upsamplingì„ ì§„í–‰í•œë‹¤. ì´ë ‡ê²Œ upsampleëœ tensorëŠ” í˜„ì¬ë³´ë‹¤ í•œ ë‹¨ê³„ ì‘ì€ scaleì˜ feature mapì„ êµ¬í•˜ëŠ” network ì´ˆë°˜ë¶€ì— feature extractorì—ì„œ ë½‘ì€ tensorì™€ concatenationì„ í†µí•´ mergeë˜ëŠ”ë°, ì´ëŠ” ë”ìš± meaningfulí•œ semantic informationì„ ì–»ê²Œ í•´ì¤€ë‹¤. 


## Loss

$$Î»_ {coord} \sum_ {i=0}^{S^2} \sum_ {j=0}^B ğŸ™^{obj}_ {i j} \left[(t_ {x_ i} - \hat{t_ {x_ i}})^2 + (t_ {y_ i} - \hat{t_ {y_ i}})^2 \right]$$

$$+Î»_ {coord} \sum_ {i=0}^{S^2} \sum_ {j=0}^B ğŸ™^{obj}_ {i j} \left[(t_ {w_ i} - \hat{t_ {w_ i}})^2 + (t_ {h_ i} - \hat{t_ {h_ i}})^2 \right]$$

$$+\sum_{i=0}^{S^2} \sum_{j=0}^B ğŸ™^{obj}_{i j} \left[-(o_i\log(\hat{o_i}) + (1 - o_i)\log(1 - \hat{o_i}))\right]$$

$$+Mask_{ig} \cdot Î»_{noobj} \sum_{i=0}^{S^2} \sum_{j=0}^B ğŸ™^{noobj}_{i j} \left[-(o_i\log(\hat{o_i}) + (1 - o_i)\log(1 - \hat{o_i}))\right]$$

$$+\sum_{i=0}^{S^2} \sum_{j=0}^B ğŸ™^{obj}_{i j} \left[-(c_i\log(\hat{c_i}) + (1 - c_i)\log(1 - \hat{c_i}))\right]$$  

$S$ : number of cells    
$B$ : number of anchors  
$o$ : objectness  
$c$ : class label  
$Î»_ {coord}$ : coordinate loss balance constant  
$Î»_{noobj}$ : no confidence loss balance constant    
$ğŸ™^{obj}_ {i j}$ : 1 when there is object, 0 when there is no object  
$ğŸ™^{noobj}_ {i j}$ : 1 when there is no object, 0 when there is object  
$Mask_{ig}$ : tensor that masks only the anchor with iou $\le$ 0.5. Have a shape of $\left[S, S, B\right]$.

$o$ (objectness)ëŠ” anchorì™€ bboxì˜ iouê°€ ê°€ì¥ í° anchorì˜ ê°’ì´ 1, ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš°ì˜ ê°’ì´ 0ì¸ $\left[N, N, 3, 1\right]$ì˜ tensorë¡œ ë§Œë“¤ì–´ì§„ë‹¤. $c$ (class label)ì€ one-encodingìœ¼ë¡œ $\left[N, N, 3, n \right]$ ($n$ : num_classes) ì˜ shapeë¥¼ ê°–ëŠ” tensorë¡œ ë§Œë“¤ì–´ì§„ë‹¤. 


# GIoU, DIoU,  CIoU
ì¼ë°˜ì ìœ¼ë¡œ IoU-based lossëŠ” ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„ëœë‹¤. 

$$L = 1 - IoU + \mathcal{R}(B, B^{gt})$$

ì—¬ê¸°ì„œ $R(B, B^{gt})$ëŠ”  predicted box $B$ì™€ target box $B^{gt}$ì— ëŒ€í•œ penalty termì´ë‹¤.  
$1 - IoU$ë¡œë§Œ Lossë¥¼ êµ¬í•  ê²½ìš° boxê°€ ê²¹ì¹˜ì§€ ì•ŠëŠ” caseì— ëŒ€í•´ì„œ ì–´ëŠ ì •ë„ì˜ ì˜¤ì°¨ë¡œ êµì§‘í•©ì´ ìƒê¸°ì§€ ì•Šì€ ê²ƒì¸ì§€ ì•Œ ìˆ˜ ì—†ì–´ì„œ gradient vanishing ë¬¸ì œê°€ ë°œìƒí–ˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ penalty termì„ ì¶”ê°€í•œ ê²ƒì´ë‹¤. 

## Generalized-IoU(GIoU)
Generalized-IoU(GIoU) ì˜ ê²½ìš° LossëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°ëœë‹¤. 

$$L_{GIoU} = 1 - IoU + \frac{|C - B âˆª B^{gt}|}{|C|}$$

ì—¬ê¸°ì„œ $C$ëŠ” $B$ì™€ $B^{gt}$ë¥¼ ëª¨ë‘ í¬í•¨í•˜ëŠ” ìµœì†Œ í¬ê¸°ì˜ Boxë¥¼ ì˜ë¯¸í•œë‹¤. Generalized-IoUëŠ” ê²¹ì¹˜ì§€ ì•ŠëŠ” ë°•ìŠ¤ì— ëŒ€í•œ gradient vanishing ë¬¸ì œëŠ” ê°œì„ í–ˆì§€ë§Œ horizontalê³¼ verticalì— ëŒ€í•´ì„œ ì—ëŸ¬ê°€ í¬ë‹¤. ì´ëŠ” target boxì™€ ìˆ˜í‰, ìˆ˜ì§ì„ ì„ ì´ë£¨ëŠ” Anchor boxì— ëŒ€í•´ì„œëŠ” $|C - B âˆª B^{gt}|$ê°€ ë§¤ìš° ì‘ê±°ë‚˜ 0ì— ê°€ê¹Œì›Œì„œ IoUì™€ ë¹„ìŠ·í•˜ê²Œ ë™ì‘í•˜ê¸° ë•Œë¬¸ì´ë‹¤. ë˜í•œ ê²¹ì¹˜ì§€ ì•ŠëŠ” boxì— ëŒ€í•´ì„œ ì¼ë‹¨ predicted boxì˜ í¬ê¸°ë¥¼ ë§¤ìš° í‚¤ìš°ê³  IoUë¥¼ ëŠ˜ë¦¬ëŠ” ë™ì‘ íŠ¹ì„± ë•Œë¬¸ì— ìˆ˜ë ´ ì†ë„ê°€ ë§¤ìš° ëŠë¦¬ë‹¤. 

## Distance-IoU(DIoU)
GIoUê°€ ë©´ì  ê¸°ë°˜ì˜ penalty termì„ ë¶€ì—¬í–ˆë‹¤ë©´, DIoUëŠ” ê±°ë¦¬ ê¸°ë°˜ì˜ penalty termì„ ë¶€ì—¬í•œë‹¤. 
DIoUì˜ penalty termì€ ë‹¤ìŒê³¼ ê°™ë‹¤. 

$$\mathcal{R}_{DIoU} = \frac{\rho^2(b, b^{gt})}{c^2}$$

$\rho^2$ëŠ” Euclideanê±°ë¦¬ì´ë©° $c$ëŠ” $B$ì™€ $B^{gt}$ë¥¼ í¬í•¨í•˜ëŠ” ê°€ì¥ ì‘ì€ Boxì˜ ëŒ€ê°ì„  ê±°ë¦¬ì´ë‹¤. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/4abe5f78-388b-459f-a3f4-95e41a5fdb0a" height="25%" width="25%"></p>

DIoU LossëŠ” ë‘ ê°œì˜ boxê°€ ì™„ë²½íˆ ì¼ì¹˜í•˜ë©´ 0, ë§¤ìš° ë©€ì–´ì§€ë©´ $L_{GIoU} = L_{DIoU} \mapsto 2$ê°€ ëœë‹¤. ì´ëŠ” IoUê°€ 0ì´ ë˜ê³ , penalty termì´ 1ì— ê°€ê¹ê²Œ ë˜ê¸° ë•Œë¬¸ì´ë‹¤. Distance-IoUëŠ” ë‘ boxì˜ ì¤‘ì‹¬ ê±°ë¦¬ë¥¼ ì§ì ‘ì ìœ¼ë¡œ ì¤„ì´ê¸° ë•Œë¬¸ì— GIoUì— ë¹„í•´ ìˆ˜ë ´ì´ ë¹ ë¥´ê³ , ê±°ë¦¬ê¸°ë°˜ì´ë¯€ë¡œ ìˆ˜í‰, ìˆ˜ì§ë°©í–¥ì—ì„œ ë˜í•œ ìˆ˜ë ´ì´ ë¹ ë¥´ë‹¤. 

## Complete-IoU(CIoU)
DIoU, CIoUë¥¼ ì œì•ˆí•œ ë…¼ë¬¸ì—ì„œ ë§í•˜ëŠ” ì„±ê³µì ì¸ Bounding Box Regressionì„ ìœ„í•œ 3ê°€ì§€ ì¡°ê±´ì€ overlap area, central point
distance, aspect ratioì´ë‹¤. ì´ ì¤‘ overlap area, central pointëŠ” DIoUì—ì„œ ì´ë¯¸ ê³ ë ¤í–ˆê³  ì—¬ê¸°ì— aspect ratioë¥¼ ê³ ë ¤í•œ penalty termì„ ì¶”ê°€í•œ ê²ƒì´ CIoUì´ë‹¤. CIoU penalty termëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ëœë‹¤. 

$$\mathcal{R}_{CIoU} = \frac{\rho^2(b, b^{gt})}{c^2} + \alpha v$$

$$v = \frac{4}{Ï€^2}(\arctan{\frac{w^{gt}}{h^{gt}}} - \arctan{\frac{w}{h}})^2$$

$$\alpha = \frac{v}{(1 - IoU) + v}$$

$v$ì˜ ê²½ìš° bboxëŠ” ì§ì‚¬ê°í˜•ì´ê³  $\arctan{\frac{w}{h}} = \theta$ì´ë¯€ë¡œ $\theta$ì˜ ì°¨ì´ë¥¼ í†µí•´ aspect ratioë¥¼ êµ¬í•˜ê²Œ ëœë‹¤. ì´ë•Œ $v$ì— $\frac{2}{Ï€}$ê°€ ê³±í•´ì§€ëŠ” ì´ìœ ëŠ” $\arctan$ í•¨ìˆ˜ì˜ ìµœëŒ€ì¹˜ê°€ $\frac{2}{Ï€}$ ì´ë¯€ë¡œ scaleì„ ì¡°ì •í•´ì£¼ê¸° ìœ„í•´ì„œì´ë‹¤. 

$\alpha$ëŠ” trade-off íŒŒë¼ë¯¸í„°ë¡œ IoUê°€ í° boxì— ëŒ€í•´ ë” í° penaltyë¥¼ ì£¼ê²Œ ëœë‹¤. 

CIoUì— ëŒ€í•´ ìµœì í™”ë¥¼ ìˆ˜í–‰í•˜ë©´ ì•„ë˜ì™€ ê°™ì€ ê¸°ìš¸ê¸°ë¥¼ ì–»ê²Œ ëœë‹¤. ì´ë•Œ, $w, h$ëŠ” ëª¨ë‘ 0ê³¼ 1ì‚¬ì´ë¡œ ê°’ì´ ì‘ì•„ gradient explosionì„ ìœ ë°œí•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ì‹¤ì œ êµ¬í˜„ ì‹œì—ëŠ” $\frac{1}{w^2 + h^2} = 1$ë¡œ ì„¤ì •í•œë‹¤. 

$$\frac{\partial v}{\partial w} = \frac{8}{Ï€^2}(\arctan{\frac{w^{gt}}{h^{gt}}} - \arctan{\frac{w}{h}}) \times \frac{h}{w^2 + h^2}$$ 

$$\frac{\partial v}{\partial h} = -\frac{8}{Ï€^2}(\arctan{\frac{w^{gt}}{h^{gt}}} - \arctan{\frac{w}{h}}) \times \frac{w}{w^2 + h^2}$$ 

# Reference
## Web Link 
One-stage object detection : https://machinethink.net/blog/object-detection/   
DIoU, CIoU : https://hongl.tistory.com/215  
YOLOv3 : https://herbwood.tistory.com/21  
&#160;&#160;&#160;&#160;&#160;ã€€ã€€ã€€ https://csm-kr.tistory.com/11    
&#160;&#160;&#160;&#160;&#160;ã€€ã€€ã€€ https://www.youtube.com/watch?v=jqykPH3jbic  
Residual block : https://daeun-computer-uneasy.tistory.com/28  
ã€€ã€€ã€€ã€€&#160;&#160;ã€€ã€€ã€€https://techblog-history-younghunjo1.tistory.com/279  
BottleNeck : https://velog.io/@lighthouse97/CNN%EC%9D%98-Bottleneck%EC%97%90-%EB%8C%80%ED%95%9C-%EC%9D%B4%ED%95%B4  


## Paper
YOLOv2 : https://arxiv.org/pdf/1612.08242.pdf      
YOLOv3 : https://arxiv.org/pdf/1804.02767.pdf  
DIoU, CIoU : https://arxiv.org/pdf/1911.08287.pdf
